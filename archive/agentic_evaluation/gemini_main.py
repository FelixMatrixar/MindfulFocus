"""
Main execution script for Gemini-powered medical pipeline evaluation
"""

import asyncio
import json
import os
from datetime import datetime
import numpy as np
from gemini_pipeline_integration import GeminiPipelineEvaluationOrchestrator

# Configuration
PROJECT_ID = "your-gcp-project-id"  # Replace with your GCP project
LOCATION = "us-central1"

def display_gemini_results(evaluation_report):
    """Display Gemini evaluation results"""
    if not evaluation_report:
        print("âŒ No results to display")
        return
    
    print("\n" + "ğŸ§  GEMINI-POWERED EVALUATION RESULTS ğŸ§ ")
    print("=" * 70)
    
    summary = evaluation_report.get('evaluation_summary', {})
    print(f"ğŸ“‹ Report ID: {evaluation_report.get('report_id', 'N/A')}")
    print(f"ğŸ¤– Model Used: {evaluation_report.get('gemini_model', 'gemini-1.5-pro')}")
    print(f"ğŸ“Š Overall Score: {summary.get('overall_score', 0):.3f}/1.0")
    print(f"ğŸ¯ Deployment Ready: {'âœ… Yes' if summary.get('deployment_ready', False) else 'âŒ No'}")
    print(f"ğŸ§  Gemini Confidence: {summary.get('gemini_confidence', 0):.3f}")
    print(f"âš ï¸ Critical Issues: {len(summary.get('critical_issues', []))}")
    
    # Show Gemini insights
    gemini_content = evaluation_report.get('gemini_report_content', '')
    if gemini_content:
        print(f"\nğŸ§  Gemini Analysis Preview:")
        print("â”€" * 50)
        print(gemini_content[:500] + "..." if len(gemini_content) > 500 else gemini_content)
    
    # Show actionable recommendations
    recommendations = evaluation_report.get('actionable_recommendations', [])
    if recommendations:
        print(f"\nğŸ¯ Gemini Recommendations:")
        print("â”€" * 40)
        for i, rec in enumerate(recommendations[:5], 1):
            print(f"  {i}. {rec}")
    
    # Show technical improvements
    improvements = evaluation_report.get('technical_improvements', [])
    if improvements:
        print(f"\nğŸ”§ Technical Improvements:")
        print("â”€" * 40)
        for i, imp in enumerate(improvements[:3], 1):
            print(f"  {i}. {imp}")
    
    # Show deployment plan
    deployment_plan = evaluation_report.get('clinical_deployment_plan', {})
    if deployment_plan:
        print(f"\nğŸš€ Deployment Plan:")
        print("â”€" * 30)
        immediate = deployment_plan.get('immediate_actions', [])
        if immediate:
            print(f"  Immediate: {immediate[0] if immediate else 'None'}")
        
        short_term = deployment_plan.get('short_term_goals', [])
        if short_term:
            print(f"  Short-term: {short_term[0] if short_term else 'None'}")

async def main():
    """Main execution function"""
    print("ğŸ§  Gemini-Powered Medical Pipeline Evaluation System")
    print("=" * 70)
    print(f"ğŸ“ Project: {PROJECT_ID}")
    print(f"ğŸŒ Location: {LOCATION}")
    
    # Verify GCP setup
    if not PROJECT_ID or PROJECT_ID == "your-gcp-project-id":
        print("âŒ Please set your GCP PROJECT_ID in the script")
        return
    
    try:
        orchestrator = GeminiPipelineEvaluationOrchestrator(PROJECT_ID, LOCATION)
        
        while True:
            print("\nğŸ¯ Gemini Evaluation Options:")
            print("1. âš¡ Quick Evaluation (60s, minimal Gemini)")
            print("2. ğŸ§  Standard Evaluation (5min, moderate Gemini)")
            print("3. ğŸ”¬ Deep Evaluation (5min, extensive Gemini)")
            print("4. ğŸ“Š Check Gemini Status")
            print("5. âŒ Exit")
            
            choice = input("\nSelect option (1-5): ").strip()
            
            if choice == "1":
                print("âš¡ Starting Quick Gemini Evaluation...")
                start_time = datetime.now()
                report = await orchestrator.run_quick_gemini_evaluation(60)
                
                if report:
                    print(f"âš¡ Quick evaluation completed in {datetime.now() - start_time}")
                    display_gemini_results(report)
                    save_report(report, "quick")
                
            elif choice == "2":
                print("ğŸ§  Starting Standard Gemini Evaluation...")
                start_time = datetime.now()
                report = await orchestrator.run_comprehensive_gemini_evaluation(300, use_detailed_analysis=False)
                
                if report:
                    print(f"ğŸ§  Standard evaluation completed in {datetime.now() - start_time}")
                    display_gemini_results(report)
                    save_report(report, "standard")
                
            elif choice == "3":
                print("ğŸ”¬ Starting Deep Gemini Evaluation...")
                start_time = datetime.now()
                report = await orchestrator.run_deep_gemini_evaluation(300)
                
                if report:
                    print(f"ğŸ”¬ Deep evaluation completed in {datetime.now() - start_time}")
                    display_gemini_results(report)
                    save_report(report, "deep")
                
            elif choice == "4":
                await check_gemini_status(PROJECT_ID, LOCATION)
                
            elif choice == "5":
                print("ğŸ‘‹ Goodbye!")
                break
                
            else:
                print("âŒ Invalid choice, please try again.")
            
            if choice in ["1", "2", "3"]:
                input("\nPress Enter to continue...")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Exiting...")
    except Exception as e:
        print(f"âŒ Error: {e}")

def save_report(report, evaluation_type):
    """Save evaluation report"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"gemini_evaluation_{evaluation_type}_{timestamp}.json"
    
    try:
        with open(filename, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        print(f"ğŸ’¾ Report saved: {filename}")
    except Exception as e:
        print(f"âš ï¸ Could not save report: {e}")

async def check_gemini_status(project_id, location):
    """Check Gemini/Vertex AI status"""
    print("ğŸ” Checking Gemini/Vertex AI status...")
    
    try:
        import vertexai
        from vertexai.generative_models import GenerativeModel
        
        # Initialize Vertex AI
        vertexai.init(project=project_id, location=location)
        
        # Test Gemini model
        model = GenerativeModel("gemini-1.5-pro")
        test_response = model.generate_content("Test connection - respond with 'OK'")
        
        print("âœ… Gemini connection successful!")
        print(f"ğŸ¤– Model: gemini-1.5-pro")
        print(f"ğŸ“ Project: {project_id}")
        print(f"ğŸŒ Location: {location}")
        print(f"ğŸ’¬ Test Response: {test_response.text[:50]}")
        
    except Exception as e:
        print(f"âŒ Gemini connection failed: {e}")
        print("\nğŸ’¡ Troubleshooting:")
        print("1. Check GCP project ID and permissions")
        print("2. Enable Vertex AI API in your project")
        print("3. Set up authentication: gcloud auth application-default login")
        print("4. Install required packages: pip install google-cloud-aiplatform")

if __name__ == "__main__":
    asyncio.run(main())